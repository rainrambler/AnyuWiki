- Reinforcement Learning with Human Feedback
- 基于人类反馈的强化学习（Reinforcement Learning with Human Feedback，RLHF）等技术实现
  了以自然语言对话为接口的 [[ChatGPT]] 模型。
- RLHF 这一概念最早是在 2008 年 TAMER：Training an Agent Manually via Evaluative Reinforcement一文中被提及。
- #AI #[[Machine learning]]
-